#!/usr/bin/env python3
"""
ç¯å¢ƒæµ‹è¯•è„šæœ¬ - éªŒè¯VoiceWakenAIé¡¹ç›®çš„ä¾èµ–ç¯å¢ƒ
"""
import sys
import importlib
import traceback

def test_import(module_name, package_name=None):
    """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
    try:
        module = importlib.import_module(module_name)
        version = getattr(module, '__version__', 'Unknown')
        print(f"âœ… {package_name or module_name}: {version}")
        return True
    except ImportError as e:
        print(f"âŒ {package_name or module_name}: Import failed - {e}")
        return False
    except Exception as e:
        print(f"âš ï¸  {package_name or module_name}: {e}")
        return False

def test_pytorch_gpu():
    """æµ‹è¯•PyTorch GPUæ”¯æŒ"""
    try:
        import torch
        print(f"ğŸ”¥ PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"ğŸ”¥ CUDAå¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"ğŸ”¥ CUDAç‰ˆæœ¬: {torch.version.cuda}")
            print(f"ğŸ”¥ GPUæ•°é‡: {torch.cuda.device_count()}")
            print(f"ğŸ”¥ GPUåç§°: {torch.cuda.get_device_name(0)}")
            
            # ç®€å•GPUæµ‹è¯•
            x = torch.randn(3, 3).cuda()
            y = torch.randn(3, 3).cuda()
            z = torch.mm(x, y)
            print(f"ğŸ”¥ GPUè®¡ç®—æµ‹è¯•: æˆåŠŸ (ç»“æœå½¢çŠ¶: {z.shape})")
        return True
    except Exception as e:
        print(f"âŒ PyTorch GPUæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("="*60)
    print("ğŸš€ VoiceWakenAI ç¯å¢ƒæµ‹è¯•")
    print("="*60)
    
    # åŸºæœ¬ä¿¡æ¯
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"Pythonè·¯å¾„: {sys.executable}")
    print("-"*60)
    
    # æ ¸å¿ƒä¾èµ–æµ‹è¯•
    core_packages = [
        ("torch", "PyTorch"),
        ("torchvision", "TorchVision"),
        ("torchaudio", "TorchAudio"),
        ("pytorch_lightning", "PyTorch Lightning"),
        ("transformers", "Transformers"),
        ("accelerate", "Accelerate"),
        ("datasets", "Datasets"),
    ]
    
    # Webæ¡†æ¶æµ‹è¯•
    web_packages = [
        ("fastapi", "FastAPI"),
        ("uvicorn", "Uvicorn"),
        ("gradio", "Gradio"),
        ("pydantic", "Pydantic"),
    ]
    
    # éŸ³é¢‘å¤„ç†æµ‹è¯•
    audio_packages = [
        ("librosa", "Librosa"),
        ("soundfile", "SoundFile"),
        ("sounddevice", "SoundDevice"),
        ("webrtcvad", "WebRTC VAD"),
    ]
    
    # æœºå™¨å­¦ä¹ æµ‹è¯•
    ml_packages = [
        ("numpy", "NumPy"),
        ("scipy", "SciPy"),
        ("sklearn", "Scikit-learn"),
        ("matplotlib", "Matplotlib"),
        ("pandas", "Pandas"),
    ]
    
    success_count = 0
    total_count = 0
    
    print("ğŸ” æ ¸å¿ƒæ·±åº¦å­¦ä¹ æ¡†æ¶:")
    for module, name in core_packages:
        if test_import(module, name):
            success_count += 1
        total_count += 1
    
    print("\nğŸŒ Webæ¡†æ¶:")
    for module, name in web_packages:
        if test_import(module, name):
            success_count += 1
        total_count += 1
    
    print("\nğŸµ éŸ³é¢‘å¤„ç†:")
    for module, name in audio_packages:
        if test_import(module, name):
            success_count += 1
        total_count += 1
    
    print("\nğŸ“Š æœºå™¨å­¦ä¹ åº“:")
    for module, name in ml_packages:
        if test_import(module, name):
            success_count += 1
        total_count += 1
    
    print("\n" + "="*60)
    print("ğŸ”¥ PyTorch GPU æµ‹è¯•:")
    test_pytorch_gpu()
    
    print("\n" + "="*60)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {success_count}/{total_count} åŒ…å¯¼å…¥æˆåŠŸ")
    
    if success_count == total_count:
        print("ğŸ‰ æ‰€æœ‰æ ¸å¿ƒä¾èµ–éƒ½å·²æ­£ç¡®å®‰è£…ï¼")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†ä¾èµ–ç¼ºå¤±ï¼Œä½†æ ¸å¿ƒåŠŸèƒ½åº”è¯¥å¯ç”¨")
        return False

if __name__ == "__main__":
    main()
